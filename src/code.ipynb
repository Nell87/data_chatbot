{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from llama_index import SimpleDirectoryReader,LLMPredictor,GPTListIndex\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import configparser\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# Read configuration file and get all the connections\n",
    "config = configparser.ConfigParser()\n",
    "config.read('my_config.ini')\n",
    "config.sections()\n",
    "os.environ['OPENAI_API_KEY'] = config['OpenAI']['password']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_posts(url):\n",
    "    # Scrape web\n",
    "    blog_json = requests.get(url).json()\n",
    "    number_posts = len(blog_json)\n",
    "\n",
    "    # Save text file per post\n",
    "    for i in range(number_posts):\n",
    "        # Title\n",
    "        title=(blog_json[i]['title']['rendered'])\n",
    "\n",
    "        # Content\n",
    "        entry_content = blog_json[i]['content']['rendered']\n",
    "        entry_text = BeautifulSoup(entry_content).get_text()\n",
    "\n",
    "        # Clean Content\n",
    "        entry_text = entry_text.replace('\\xa0', '') \n",
    "        entry_text = entry_text.replace('\\n3', '') \n",
    "        entry_text = entry_text.replace('\\n1', '') \n",
    "        entry_text = entry_text.replace('\\n', ' ') \n",
    "\n",
    "        # Save text\n",
    "        with open(\"../data/\"+title+'.txt', 'w') as f:\n",
    "            f.write(entry_text)     \n",
    "\n",
    "\n",
    "def train_LLM(source):\n",
    "    # Read documents to train the LLM\n",
    "    docs  = SimpleDirectoryReader(source).load_data()\n",
    "\n",
    "    # Training\n",
    "    llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0.7, model_name=\"gpt-3.5-turbo\", max_tokens=512))\n",
    "    output_index = GPTListIndex.from_documents(docs)\n",
    "\n",
    "    # Engine\n",
    "    engine = output_index.as_query_engine()\n",
    "\n",
    "    return engine\n",
    "\n",
    "def question_LLM(engine, question):\n",
    "    response = engine.query(question)   \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.saramarlop.com/wp-json/wp/v2/posts'\n",
    "question = \"What is this document about?\"\n",
    "source = \"../data\"\n",
    "\n",
    "scrape_all_posts(url = url)\n",
    "engine = train_LLM(source = source)\n",
    "response = question_LLM(engine = engine, question =  question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis document is about the concept of Large Language Models (LLM) and how they relate to Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), and Generative AI. It also discusses the cognitive bias of scope insensitivity and the martial art of rationality.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
